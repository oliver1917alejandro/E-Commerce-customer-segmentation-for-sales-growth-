{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "         #ANÁLISIS DE DATOS DE E-COMMERCE - PROYECTO \n",
        "\n",
        "# Importamos las bibliotecas necesarias\n",
        "import pandas as pd      \n",
        "import numpy as np       \n",
        "import matplotlib.pyplot as plt  \n",
        "import seaborn as sns    \n",
        "import os                \n",
        "from datetime import datetime  \n",
        "from matplotlib.ticker import FuncFormatter  \n",
        "\n",
        "# Cargamos los \n",
        "clientes = pd.read_csv('customers_dataset.csv')\n",
        "ubicaciones = pd.read_csv('geolocation_dataset.csv') \n",
        "pagos = pd.read_csv('order_payments_dataset.csv')\n",
        "productos = pd.read_csv('products_dataset.csv')\n",
        "vendedores = pd.read_csv('sellers_dataset.csv')\n",
        "ordenes = pd.read_csv('orders_dataset.csv')\n",
        "items_ordenes = pd.read_csv('order_items_dataset.csv')\n",
        "reviews = pd.read_csv('order_reviews_dataset.csv')\n",
        "traduccion_categorias = pd.read_csv('product_category_name_translation.csv')\n",
        "\n",
        "# LIMPIEZA Y PREPARACIÓN DE DATOS (DATA WRANGLING)\n",
        "\n",
        "print(\"Iniciando proceso de limpieza y preparación de datos...\")\n",
        "\n",
        "# 1. Verificación de datos faltantes\n",
        "print(\"\\n--- Verificando valores faltantes ---\")\n",
        "print(\"Clientes - valores faltantes:\", clientes.isnull().sum().sum())\n",
        "print(\"Ubicaciones - valores faltantes:\", ubicaciones.isnull().sum().sum())\n",
        "print(\"Pagos - valores faltantes:\", pagos.isnull().sum().sum())\n",
        "print(\"Productos - valores faltantes:\", productos.isnull().sum().sum())\n",
        "print(\"Vendedores - valores faltantes:\", vendedores.isnull().sum().sum())\n",
        "print(\"Ordenes - valores faltantes:\", ordenes.isnull().sum().sum())\n",
        "print(\"Items ordenes - valores faltantes:\", items_ordenes.isnull().sum().sum())\n",
        "print(\"Reviews - valores faltantes:\", reviews.isnull().sum().sum())\n",
        "\n",
        "# 2. Limpieza de datos - Eliminamos duplicados\n",
        "clientes = clientes.drop_duplicates()\n",
        "ubicaciones = ubicaciones.drop_duplicates()\n",
        "pagos = pagos.drop_duplicates()\n",
        "productos = productos.drop_duplicates()\n",
        "vendedores = vendedores.drop_duplicates()\n",
        "ordenes = ordenes.drop_duplicates()\n",
        "items_ordenes = items_ordenes.drop_duplicates()\n",
        "reviews = reviews.drop_duplicates()\n",
        "\n",
        "# 3. Convertimos fechas a formato datetime\n",
        "# Convertimos las fechas en la tabla de órdenes\n",
        "ordenes['order_purchase_timestamp'] = pd.to_datetime(ordenes['order_purchase_timestamp'])\n",
        "ordenes['order_approved_at'] = pd.to_datetime(ordenes['order_approved_at'])\n",
        "ordenes['order_delivered_carrier_date'] = pd.to_datetime(ordenes['order_delivered_carrier_date'])\n",
        "ordenes['order_delivered_customer_date'] = pd.to_datetime(ordenes['order_delivered_customer_date'])\n",
        "ordenes['order_estimated_delivery_date'] = pd.to_datetime(ordenes['order_estimated_delivery_date'])\n",
        "\n",
        "# Convertimos las fechas en la tabla de reviews\n",
        "reviews['review_creation_date'] = pd.to_datetime(reviews['review_creation_date'])\n",
        "reviews['review_answer_timestamp'] = pd.to_datetime(reviews['review_answer_timestamp'])\n",
        "\n",
        "# 4. Identificamos valores extremos en precios\n",
        "precio_promedio = items_ordenes['price'].mean()\n",
        "precio_desviacion = items_ordenes['price'].std()\n",
        "precio_minimo = items_ordenes['price'].min()\n",
        "precio_maximo = items_ordenes['price'].max()\n",
        "\n",
        "print(\"\\n--- Análisis de precios ---\")\n",
        "print(\"Precio promedio:\", precio_promedio)\n",
        "print(\"Precio mínimo:\", precio_minimo)\n",
        "print(\"Precio máximo:\", precio_maximo)\n",
        "\n",
        "# 5. Traducción de categorías de productos\n",
        "productos = productos.merge(traduccion_categorias, on='product_category_name', how='left')\n",
        "\n",
        "# 6. Creamos columnas nuevas útiles\n",
        "# Añadimos mes y año a las órdenes\n",
        "ordenes['mes_compra'] = ordenes['order_purchase_timestamp'].dt.month\n",
        "ordenes['año_compra'] = ordenes['order_purchase_timestamp'].dt.year\n",
        "\n",
        "# Calculamos tiempo de entrega en días\n",
        "ordenes['tiempo_entrega'] = (ordenes['order_delivered_customer_date'] - ordenes['order_purchase_timestamp']).dt.days\n",
        "\n",
        "# 7. Mostramos información después de la limpieza\n",
        "print(\"\\n--- Resumen de datos después de la limpieza ---\")\n",
        "print(\"Clientes:\", clientes.shape[0], \"filas\")\n",
        "print(\"Ubicaciones:\", ubicaciones.shape[0], \"filas\")\n",
        "print(\"Pagos:\", pagos.shape[0], \"filas\")\n",
        "print(\"Productos:\", productos.shape[0], \"filas\")\n",
        "print(\"Vendedores:\", vendedores.shape[0], \"filas\")\n",
        "print(\"Ordenes:\", ordenes.shape[0], \"filas\")\n",
        "print(\"Items ordenes:\", items_ordenes.shape[0], \"filas\")\n",
        "print(\"Reviews:\", reviews.shape[0], \"filas\")\n",
        "\n",
        "print(\"\\nProceso de limpieza y preparación de datos completado.\")\n",
        "\n",
        "# RFM ANALYSIS\n",
        "\n",
        "# Calculamos la fecha más reciente en el dataset\n",
        "fecha_maxima = ordenes['order_purchase_timestamp'].max()\n",
        "\n",
        "# Unimos las tablas necesarias para el análisis RFM\n",
        "df_rfm = ordenes.merge(items_ordenes, on='order_id')\n",
        "\n",
        "# Calculamos los componentes del RFM por cliente\n",
        "rfm_data = df_rfm.groupby('customer_id').agg({\n",
        "    'order_purchase_timestamp': lambda x: (fecha_maxima - x.max()).days,  # Recency\n",
        "    'order_id': 'nunique',  # Frequency\n",
        "    'price': 'sum'  # Monetary\n",
        "}).rename(columns={\n",
        "    'order_purchase_timestamp': 'recency',\n",
        "    'order_id': 'frequency',\n",
        "    'price': 'monetary'\n",
        "})\n",
        "\n",
        "# Verificamos los resultados del cálculo RFM\n",
        "print(\"Análisis RFM - Primeras filas:\")\n",
        "print(rfm_data.head())\n",
        "\n",
        "# Estadísticas descriptivas del RFM\n",
        "print(\"\\nEstadísticas descriptivas del RFM:\")\n",
        "print(rfm_data.describe())\n",
        "\n",
        "# Segmentación de clientes basada en RFM\n",
        "# Dividimos cada métrica en 5 segmentos (quintiles)\n",
        "quintiles = rfm_data.rank(pct=True).applymap(lambda x: int(x * 5) + 1)\n",
        "\n",
        "# Invertimos la recencia (menor recencia = mejor puntuación)\n",
        "quintiles['recency'] = 6 - quintiles['recency']\n",
        "\n",
        "# Creamos una puntuación RFM combinada\n",
        "rfm_data['rfm_score'] = quintiles['recency'] * 100 + quintiles['frequency'] * 10 + quintiles['monetary']\n",
        "\n",
        "# Clasificamos a los clientes según su puntuación\n",
        "def clasificar_cliente(row):\n",
        "    if row['rfm_score'] >= 432:\n",
        "        return 'Campeones'\n",
        "    elif row['rfm_score'] >= 332:\n",
        "        return 'Leales'\n",
        "    elif row['rfm_score'] >= 232:\n",
        "        return 'Potenciales'\n",
        "    elif row['rfm_score'] >= 132:\n",
        "        return 'En riesgo'\n",
        "    else:\n",
        "        return 'Necesitan atención'\n",
        "\n",
        "rfm_data['segmento'] = rfm_data.apply(clasificar_cliente, axis=1)\n",
        "\n",
        "# Visualizamos la distribución de segmentos\n",
        "sns.set_style(\"whitegrid\") # 1. Seaborn Style\n",
        "plt.figure(figsize=(12, 7)) # Adjusted figure size for better label display\n",
        "ax = sns.countplot(x='segmento', data=rfm_data, order=rfm_data['segmento'].value_counts().index, palette=\"viridis\", edgecolor='black') # 2. Color Palette, 5. Bar Edge Color\n",
        "plt.title('Distribución de Clientes por Segmento RFM', fontsize=16) # 4. Font Size, 6. Clarity\n",
        "plt.xlabel('Segmento', fontsize=14) # 4. Font Size\n",
        "plt.ylabel('Número de Clientes', fontsize=14) # 4. Font Size\n",
        "plt.xticks(rotation=45, fontsize=12) # 4. Font Size\n",
        "# 3. Data Labels\n",
        "for p in ax.patches:\n",
        "    ax.annotate(f'{p.get_height():.0f}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha='center', va='center', fontsize=11, color='black', xytext=(0, 5),\n",
        "                textcoords='offset points')\n",
        "plt.tight_layout()\n",
        "plt.savefig('segmentos_rfm.png') # 7. Save\n",
        "plt.close() # 7. Close\n",
        "\n",
        "print(\"\\nDistribución de clientes por segmento:\")\n",
        "print(rfm_data['segmento'].value_counts())\n",
        "# Análisis más profundo de los segmentos\n",
        "\n",
        "# Estadísticas descriptivas por segmento\n",
        "print(\"\\nEstadísticas por segmento:\")\n",
        "segment_stats = rfm_data.groupby('segmento').agg({\n",
        "    'recency': ['mean', 'min', 'max'],\n",
        "    'frequency': ['mean', 'min', 'max'],\n",
        "    'monetary': ['mean', 'min', 'max']\n",
        "})\n",
        "print(segment_stats)\n",
        "\n",
        "# Visualización de las métricas RFM por segmento\n",
        "fig, axes = plt.subplots(3, 1, figsize=(15, 12)) # Adjusted figsize\n",
        "fig.suptitle('Análisis Detallado de Métricas RFM por Segmento', fontsize=18) # 3. Overall Figure Title, 5. Font Sizes\n",
        "order_segmentos = ['Campeones', 'Leales', 'Potenciales', 'En riesgo', 'Necesitan atención']\n",
        "\n",
        "# Recencia promedio por segmento\n",
        "ax1 = axes[0]\n",
        "sns.barplot(x='segmento', y='recency', data=rfm_data, estimator=np.mean, \n",
        "            order=order_segmentos, ax=ax1, palette=\"viridis\", edgecolor='black') # 2. Color Palette, 6. Bar Edge Color\n",
        "ax1.set_title('Recencia Promedio por Segmento', fontsize=14) # 5. Font Sizes\n",
        "ax1.set_ylabel('Recencia Promedio (Días)', fontsize=12) # 7. Y-axis Labels, 5. Font Sizes\n",
        "ax1.set_xlabel('') # 8. X-axis Labels (remove)\n",
        "ax1.tick_params(axis='x', rotation=45, labelsize=10) # 5. Font Sizes\n",
        "for p in ax1.patches: # 4. Data Labels\n",
        "    ax1.annotate(f'{p.get_height():.0f}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha='center', va='center', fontsize=9, color='black', xytext=(0, 5),\n",
        "                textcoords='offset points')\n",
        "\n",
        "# Frecuencia promedio por segmento\n",
        "ax2 = axes[1]\n",
        "sns.barplot(x='segmento', y='frequency', data=rfm_data, estimator=np.mean,\n",
        "            order=order_segmentos, ax=ax2, palette=\"viridis\", edgecolor='black') # 2. Color Palette, 6. Bar Edge Color\n",
        "ax2.set_title('Frecuencia Promedio por Segmento', fontsize=14) # 5. Font Sizes\n",
        "ax2.set_ylabel('Frecuencia Promedio (Pedidos)', fontsize=12) # 7. Y-axis Labels, 5. Font Sizes\n",
        "ax2.set_xlabel('') # 8. X-axis Labels (remove)\n",
        "ax2.tick_params(axis='x', rotation=45, labelsize=10) # 5. Font Sizes\n",
        "for p in ax2.patches: # 4. Data Labels\n",
        "    ax2.annotate(f'{p.get_height():.0f}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha='center', va='center', fontsize=9, color='black', xytext=(0, 5),\n",
        "                textcoords='offset points')\n",
        "\n",
        "# Valor monetario promedio por segmento\n",
        "ax3 = axes[2]\n",
        "sns.barplot(x='segmento', y='monetary', data=rfm_data, estimator=np.mean,\n",
        "            order=order_segmentos, ax=ax3, palette=\"viridis\", edgecolor='black') # 2. Color Palette, 6. Bar Edge Color\n",
        "ax3.set_title('Valor Monetario Promedio por Segmento', fontsize=14) # 5. Font Sizes\n",
        "ax3.set_ylabel('Valor Monetario Promedio ($)', fontsize=12) # 7. Y-axis Labels, 5. Font Sizes\n",
        "ax3.set_xlabel('') # 8. X-axis Labels (remove)\n",
        "ax3.tick_params(axis='x', rotation=45, labelsize=10) # 5. Font Sizes\n",
        "for p in ax3.patches: # 4. Data Labels\n",
        "    ax3.annotate(f'{p.get_height():.2f}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha='center', va='center', fontsize=9, color='black', xytext=(0, 5),\n",
        "                textcoords='offset points')\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.96]) # 9. Layout (adjust for suptitle)\n",
        "plt.savefig('metricas_por_segmento.png') # 10. Save\n",
        "plt.close() # 10. Close\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# HEATMAP DE MÉTRICAS RFM PROMEDIO POR SEGMENTO\n",
        "\n",
        "# 1. Preparamos los datos para el heatmap\n",
        "segment_metrics_avg = rfm_data.groupby('segmento').agg(\n",
        "    recency_avg=('recency', 'mean'),\n",
        "    frequency_avg=('frequency', 'mean'),\n",
        "    monetary_avg=('monetary', 'mean')\n",
        ")\n",
        "segment_order = ['Campeones', 'Leales', 'Potenciales', 'En riesgo', 'Necesitan atención']\n",
        "segment_metrics_avg = segment_metrics_avg.reindex(segment_order)\n",
        "\n",
        "# Renombrar columnas para el heatmap\n",
        "segment_metrics_avg.columns = ['Recencia Promedio', 'Frecuencia Promedio', 'Valor Monetario Promedio']\n",
        "\n",
        "# 2. Creamos el heatmap\n",
        "plt.figure(figsize=(12, 7)) # Adjusted figsize\n",
        "sns.heatmap(segment_metrics_avg, annot=True, fmt=\".1f\", cmap=\"viridis\", linewidths=.5, cbar_kws={'label': 'Escala de Valores'})\n",
        "plt.title('Heatmap de Métricas RFM Promedio por Segmento', fontsize=16)\n",
        "plt.ylabel('Segmento de Cliente', fontsize=12)\n",
        "plt.xlabel('Métricas RFM Promedio', fontsize=12)\n",
        "plt.xticks(rotation=45, ha=\"right\") # Rotate x-axis labels for better fit\n",
        "plt.yticks(fontsize=10)\n",
        "plt.tight_layout()\n",
        "plt.savefig('rfm_heatmap_segmentos.png')\n",
        "plt.close()\n",
        "\n",
        "print(\"\\nHeatmap de métricas RFM por segmento guardado como 'rfm_heatmap_segmentos.png'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SCATTER PLOT DE RECENCIA VS. FRECUENCIA (COLOR/TAMAÑO POR VALOR MONETARIO)\n",
        "\n",
        "# 1. Preparamos los datos (usamos rfm_data directamente)\n",
        "#    Considerar muestreo si el dataset es muy grande y el plot es lento o muy denso:\n",
        "#    plot_data = rfm_data.sample(n=20000, random_state=42) if len(rfm_data) > 20000 else rfm_data\n",
        "plot_data = rfm_data # Usar rfm_data directamente primero\n",
        "\n",
        "# 2. Creamos el scatter plot\n",
        "plt.figure(figsize=(14, 9)) # Adjusted figsize\n",
        "scatter_plot = sns.scatterplot(\n",
        "    x='recency',\n",
        "    y='frequency',\n",
        "    hue='monetary',\n",
        "    size='monetary',  # Optional: use monetary value for size as well\n",
        "    sizes=(20, 200),  # Range of point sizes\n",
        "    palette='viridis',\n",
        "    data=plot_data,\n",
        "    alpha=0.6, # Adjust alpha for point transparency if there's overplotting\n",
        "    edgecolor='black', # Add edgecolor to points\n",
        "    linewidth=0.5\n",
        ")\n",
        "\n",
        "plt.title('Relación Recencia vs. Frecuencia (Color/Tamaño por Valor Monetario)', fontsize=16)\n",
        "plt.xlabel('Recencia (Días desde última compra)', fontsize=12)\n",
        "plt.ylabel('Frecuencia (Número de Pedidos)', fontsize=12)\n",
        "\n",
        "# Mejorar la leyenda\n",
        "handles, labels = scatter_plot.get_legend_handles_labels()\n",
        "# Podría ser necesario ajustar la leyenda si es muy larga o compleja,\n",
        "# por ahora, se usa la leyenda por defecto que genera seaborn.\n",
        "# Ejemplo: plt.legend(title='Valor Monetario', loc='upper right', bbox_to_anchor=(1.25, 1))\n",
        "\n",
        "plt.xticks(fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.tight_layout()\n",
        "plt.savefig('rfm_scatter_recency_frequency.png')\n",
        "plt.close()\n",
        "\n",
        "print(\"\\nScatter plot de Recencia vs. Frecuencia guardado como 'rfm_scatter_recency_frequency.png'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Recomendaciones de marketing basadas en segmentos\n",
        "print(\"\\nRecomendaciones de marketing por segmento:\")\n",
        "print(\"1. Campeones: Programas de fidelización, convertirlos en embajadores de marca\")\n",
        "print(\"2. Leales: Venta cruzada, programas de referidos\")\n",
        "print(\"3. Potenciales: Ofertas personalizadas, incentivos para aumentar frecuencia\")\n",
        "print(\"4. En riesgo: Campañas de reactivación, descuentos especiales\")\n",
        "print(\"5. Necesitan atención: Recordatorios, ofertas de bienvenida nuevamente\")\n",
        "\n",
        "# Exportamos los resultados para uso en campañas de marketing\n",
        "rfm_data.to_csv('segmentacion_clientes_rfm.csv', index=True)\n",
        "print(\"\\nResultados exportados a 'segmentacion_clientes_rfm.csv'\")\n",
        "\n",
        "\n",
        "   \n",
        "    \n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Iniciando proceso de limpieza y preparación de datos...\n\n--- Verificando valores faltantes ---\nClientes - valores faltantes: 0\nUbicaciones - valores faltantes: 0\nPagos - valores faltantes: 0\nProductos - valores faltantes: 2448\nVendedores - valores faltantes: 0\nOrdenes - valores faltantes: 4908\nItems ordenes - valores faltantes: 0\nReviews - valores faltantes: 145903\n\n--- Análisis de precios ---\nPrecio promedio: 120.65373901464716\nPrecio mínimo: 0.85\nPrecio máximo: 6735.0\n\n--- Resumen de datos después de la limpieza ---\nClientes: 99441 filas\nUbicaciones: 738332 filas\nPagos: 103886 filas\nProductos: 32951 filas\nVendedores: 3095 filas\nOrdenes: 99441 filas\nItems ordenes: 112650 filas\nReviews: 99224 filas\n\nProceso de limpieza y preparación de datos completado.\nAnálisis RFM - Primeras filas:\n                                  recency  frequency  monetary\ncustomer_id                                                   \n00012a2ce6f8dcda20d059ce98491703      337          1     89.80\n000161a058600d5901f007fab4c27140      458          1     54.90\n0001fd6190edaaf884bcaf3d49edf079      596          1    179.99\n0002414f95344307404f0ace7a26f1d5      427          1    149.90\n000379cdec625522490c315e70c7a9fb      198          1     93.00\n\nEstadísticas descriptivas del RFM:\n            recency  frequency      monetary\ncount  98666.000000    98666.0  98666.000000\nmean     289.343067        1.0    137.754076\nstd      153.389890        0.0    210.645145\nmin       44.000000        1.0      0.850000\n25%      165.000000        1.0     45.900000\n50%      270.000000        1.0     86.900000\n75%      399.000000        1.0    149.900000\nmax      772.000000        1.0  13440.000000\n\nDistribución de clientes por segmento:\nCampeones             35592\nPotenciales           19965\nLeales                19540\nEn riesgo             19393\nNecesitan atención     4176\nName: segmento, dtype: int64\n\nEstadísticas por segmento:\n                       recency           frequency            monetary        \\\n                          mean  min  max      mean min max        mean   min   \nsegmento                                                                       \nCampeones           135.704203   44  228       1.0   1   1  152.657874  2.20   \nEn riesgo           493.394627  320  772       1.0   1   1  140.203971  2.29   \nLeales              255.327636  145  319       1.0   1   1  131.266981  0.85   \nNecesitan atención  528.019397  435  744       1.0   1   1   24.744351  2.90   \nPotenciales         348.401002  229  434       1.0   1   1  138.791877  2.99   \n\n                             \n                        max  \nsegmento                     \nCampeones            7160.0  \nEn riesgo            6735.0  \nLeales               3690.0  \nNecesitan atención     39.0  \nPotenciales         13440.0  \n\nRecomendaciones de marketing por segmento:\n1. Campeones: Programas de fidelización, convertirlos en embajadores de marca\n2. Leales: Venta cruzada, programas de referidos\n3. Potenciales: Ofertas personalizadas, incentivos para aumentar frecuencia\n4. En riesgo: Campañas de reactivación, descuentos especiales\n5. Necesitan atención: Recordatorios, ofertas de bienvenida nuevamente\n\nResultados exportados a 'segmentacion_clientes_rfm.csv'\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1746748618098
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.10 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}